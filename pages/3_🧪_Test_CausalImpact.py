"""
P√°gina de diagn√≥stico para CausalImpact
Guardar como: pages/3_üß™_Test_CausalImpact.py
"""
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

st.set_page_config(
    page_title="Test CausalImpact",
    page_icon="üß™",
    layout="wide"
)

st.title("üß™ Diagn√≥stico de CausalImpact")
st.markdown("Herramienta para diagnosticar problemas con el an√°lisis de Causal Impact")

# ============================================================================
# TEST 1: Verificar instalaci√≥n
# ============================================================================
st.header("1Ô∏è‚É£ Verificar Instalaci√≥n")

try:
    from causalimpact import CausalImpact
    st.success("‚úÖ pycausalimpact est√° instalado")
    
    try:
        import pkg_resources
        version = pkg_resources.get_distribution("pycausalimpact").version
        st.info(f"Versi√≥n: {version}")
    except:
        st.warning("Versi√≥n: No se pudo determinar")
except ImportError:
    st.error("‚ùå pycausalimpact NO est√° instalado")
    st.code("pip install pycausalimpact")
    st.stop()

# ============================================================================
# TEST 2: Crear datos de prueba
# ============================================================================
st.header("2Ô∏è‚É£ Crear Datos de Prueba")

if st.button("üé≤ Generar Datos de Prueba", type="primary"):
    np.random.seed(42)
    
    # Generar 90 d√≠as
    dates = pd.date_range(start='2024-01-01', periods=90, freq='D')
    baseline = 1000
    
    # Pre: normal, Post: +20%
    pre_data = baseline + np.random.normal(0, 100, 60)
    post_data = baseline * 1.2 + np.random.normal(0, 100, 30)
    sessions = np.concatenate([pre_data, post_data])
    
    df = pd.DataFrame({
        'date': dates,
        'sessions': sessions
    })
    
    st.session_state['test_data'] = df
    st.session_state['intervention_date'] = pd.Timestamp('2024-03-01')
    
    st.success(f"‚úÖ Generados {len(df)} d√≠as de datos")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("D√≠as totales", len(df))
    with col2:
        st.metric("Media Pre", f"{sessions[:60].mean():.0f}")
    with col3:
        st.metric("Media Post", f"{sessions[60:].mean():.0f}")
    
    st.info("üìä Cambio real simulado: **+20%**")

# ============================================================================
# TEST 3: Mostrar datos
# ============================================================================
if 'test_data' in st.session_state:
    st.header("3Ô∏è‚É£ Datos Generados")
    
    df = st.session_state['test_data']
    intervention = st.session_state['intervention_date']
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìã Vista de Tabla")
        st.dataframe(df, height=300)
    
    with col2:
        st.subheader("üìà Gr√°fico")
        import plotly.graph_objects as go
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=df['date'],
            y=df['sessions'],
            mode='lines',
            name='Sesiones'
        ))
        
        fig.add_vline(
            x=intervention,
            line_dash="dash",
            line_color="red",
            annotation_text="Intervenci√≥n"
        )
        
        st.plotly_chart(fig, use_container_width=True)

# ============================================================================
# TEST 4: Ejecutar CausalImpact
# ============================================================================
if 'test_data' in st.session_state:
    st.header("4Ô∏è‚É£ Ejecutar CausalImpact")
    
    if st.button("üöÄ Ejecutar An√°lisis", type="primary"):
        
        df = st.session_state['test_data']
        intervention = st.session_state['intervention_date']
        
        with st.spinner("Ejecutando CausalImpact..."):
            
            # Preparar datos
            df_analysis = df.set_index('date')[['sessions']]
            df_analysis.index = pd.DatetimeIndex(df_analysis.index, freq='D')
            
            # Definir per√≠odos
            pre_start = df_analysis.index.min()
            pre_end = intervention - pd.Timedelta(days=1)
            post_start = intervention
            post_end = df_analysis.index.max()
            
            pre_period = [pre_start, pre_end]
            post_period = [post_start, post_end]
            
            st.info(f"""
            **Per√≠odos:**
            - Pre: {pre_start.date()} a {pre_end.date()} ({(pre_end - pre_start).days + 1} d√≠as)
            - Post: {post_start.date()} a {post_end.date()} ({(post_end - post_start).days + 1} d√≠as)
            """)
            
            # Ejecutar
            try:
                ci = CausalImpact(
                    df_analysis,
                    pre_period,
                    post_period,
                    model_args={'nseasons': 7}
                )
                st.success("‚úÖ CausalImpact ejecutado con nseasons=7")
            except TypeError:
                st.warning("‚ö†Ô∏è TypeError con nseasons, intentando sin ese par√°metro...")
                ci = CausalImpact(
                    df_analysis,
                    pre_period,
                    post_period
                )
                st.success("‚úÖ CausalImpact ejecutado (sin nseasons)")
            
            st.session_state['ci_result'] = ci

# ============================================================================
# TEST 5: Examinar resultado
# ============================================================================
if 'ci_result' in st.session_state:
    st.header("5Ô∏è‚É£ Examinar Resultado")
    
    ci = st.session_state['ci_result']
    
    # Atributos
    with st.expander("üîç Ver Atributos del Objeto", expanded=False):
        attrs = [attr for attr in dir(ci) if not attr.startswith('_')]
        st.write("Atributos disponibles:")
        st.code(", ".join(attrs[:30]))
    
    # Summary
    st.subheader("üìä Summary")
    
    if hasattr(ci, 'summary_data'):
        st.success("‚úÖ Encontrado: ci.summary_data")
        summary = ci.summary_data
        st.write(f"**Type:** {type(summary)}")
        
        if isinstance(summary, pd.DataFrame):
            st.write(f"**Shape:** {summary.shape}")
            st.write(f"**Index:** {summary.index.tolist()}")
            st.write(f"**Columns:** {summary.columns.tolist()}")
            st.dataframe(summary)
        else:
            st.write(summary)
    
    elif hasattr(ci, 'summary'):
        st.success("‚úÖ Encontrado: ci.summary()")
        try:
            summary = ci.summary()
            st.write(f"**Type:** {type(summary)}")
            if isinstance(summary, pd.DataFrame):
                st.dataframe(summary)
            else:
                st.write(summary)
        except Exception as e:
            st.error(f"Error llamando summary(): {e}")
    else:
        st.error("‚ùå No se encontr√≥ ni summary_data ni summary()")
    
    # Inferences
    st.subheader("üìà Inferences")
    
    if hasattr(ci, 'inferences'):
        st.success("‚úÖ Encontrado: ci.inferences")
        inferences = ci.inferences
        
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**Shape:** {inferences.shape}")
            st.write(f"**Columns:** {inferences.columns.tolist()}")
        
        with col2:
            st.write("**Primeras filas:**")
            st.dataframe(inferences.head(3))
        
        st.markdown("---")
        st.write("**√öltimas filas:**")
        st.dataframe(inferences.tail(3))
        
        # Calcular m√©tricas manualmente
        st.subheader("üî¢ M√©tricas Calculadas Manualmente")
        
        intervention = st.session_state['intervention_date']
        post_mask = inferences.index >= intervention
        
        actual_post = inferences.loc[post_mask, 'response']
        pred_post = inferences.loc[post_mask, 'preds']
        
        actual_mean = actual_post.mean()
        pred_mean = pred_post.mean()
        effect_mean = actual_mean - pred_mean
        rel_effect = (effect_mean / pred_mean) * 100 if pred_mean != 0 else 0
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Actual Promedio", f"{actual_mean:.2f}")
        with col2:
            st.metric("Predicho Promedio", f"{pred_mean:.2f}")
        with col3:
            st.metric("Efecto Absoluto", f"{effect_mean:.2f}")
        with col4:
            st.metric("Efecto Relativo", f"{rel_effect:.2f}%")
        
        st.markdown("---")
        
        actual_sum = actual_post.sum()
        pred_sum = pred_post.sum()
        effect_sum = actual_sum - pred_sum
        rel_effect_cum = (effect_sum / pred_sum) * 100 if pred_sum != 0 else 0
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Actual Acumulado", f"{actual_sum:.2f}")
        with col2:
            st.metric("Predicho Acumulado", f"{pred_sum:.2f}")
        with col3:
            st.metric("Efecto Acumulado", f"{effect_sum:.2f}")
        with col4:
            st.metric("Efecto Relativo Acum.", f"{rel_effect_cum:.2f}%")
        
        # Comparar con lo esperado
        st.markdown("---")
        expected_effect = 20.0  # Sabemos que simulamos +20%
        
        if abs(rel_effect - expected_effect) < 5:
            st.success(f"‚úÖ El efecto calculado ({rel_effect:.1f}%) est√° cerca del esperado (+20%)")
        else:
            st.warning(f"‚ö†Ô∏è El efecto calculado ({rel_effect:.1f}%) difiere del esperado (+20%)")
    
    else:
        st.error("‚ùå No se encontr√≥ inferences")
    
    # P-value
    st.subheader("üìä P-value")
    if hasattr(ci, 'p_value'):
        p_val = ci.p_value
        st.metric("P-value", f"{p_val:.4f}")
        
        if p_val < 0.05:
            st.success("‚úÖ Resultado estad√≠sticamente significativo (p < 0.05)")
        else:
            st.warning("‚ö†Ô∏è Resultado NO significativo (p ‚â• 0.05)")
    else:
        st.error("‚ùå No se encontr√≥ p_value")

# ============================================================================
# RESUMEN
# ============================================================================
if 'ci_result' in st.session_state:
    st.markdown("---")
    st.header("üìã Resumen del Diagn√≥stico")
    
    checks = []
    
    # Check instalaci√≥n
    try:
        from causalimpact import CausalImpact
        checks.append(("pycausalimpact instalado", True))
    except:
        checks.append(("pycausalimpact instalado", False))
    
    # Check ejecuci√≥n
    if 'ci_result' in st.session_state:
        checks.append(("CausalImpact ejecutado", True))
    else:
        checks.append(("CausalImpact ejecutado", False))
    
    # Check summary
    ci = st.session_state.get('ci_result')
    if ci and (hasattr(ci, 'summary_data') or hasattr(ci, 'summary')):
        checks.append(("Summary disponible", True))
    else:
        checks.append(("Summary disponible", False))
    
    # Check inferences
    if ci and hasattr(ci, 'inferences'):
        checks.append(("Inferences disponible", True))
    else:
        checks.append(("Inferences disponible", False))
    
    # Mostrar checks
    for name, status in checks:
        if status:
            st.success(f"‚úÖ {name}")
        else:
            st.error(f"‚ùå {name}")
    
    st.markdown("---")
    
    # Recomendaciones
    st.info("""
    **üí° Informaci√≥n Clave para tu C√≥digo:**
    
    1. Usa `ci.inferences` para acceder a los datos
    2. Las columnas son: `response`, `preds`, `preds_lower`, `preds_upper`
    3. Si `summary_data` est√° vac√≠o, calcula manualmente desde `inferences`
    4. Filtra el per√≠odo post usando: `inferences.index >= intervention_date`
    """)

# ============================================================================
# FOOTER
# ============================================================================
st.markdown("---")
st.caption("AccurateMetrics - Herramienta de Diagn√≥stico CausalImpact")
